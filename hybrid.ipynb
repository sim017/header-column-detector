{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88ab0900-87cc-47fa-9ae6-317719016675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simranbawkar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/simranbawkar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9dd4b46f-4845-4b0e-951c-1a44e64bc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleAugmentedRFE(RandomForestClassifier):\n",
    "    def __init__(self, base_model: RandomForestClassifier, rules: Dict, **base_params):\n",
    "        self.base_model = base_model\n",
    "        self.rules = rules\n",
    "        self.base_model.set_params(**base_params)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Rule Augmented Estimator:\\n\\n\\t Base Model: {}\\n\\t Rules: {}\".format(self.base_model, self.rules)\n",
    "\n",
    "    def __str__(self):\n",
    "         return self.__str__\n",
    "\n",
    "        \n",
    "    def fit(self, X:pd.DataFrame, y:pd.Series, **kwargs):\n",
    "        train_x, train_y = self.getBaseModelData(X,y)\n",
    "        self.base_model.fit(train_x, train_y, **kwargs)\n",
    "        print('model fit')\n",
    "    \n",
    "    def getBaseModelData(self, X:pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        train_x = X\n",
    "        for category,rules in self.rules.items():\n",
    "            if category not in train_x.columns.values:\n",
    "                continue\n",
    "            for rule in rules:\n",
    "                if rule[0] == \"=\":\n",
    "                    train_x = train_x.loc[train_x[category]!=rule[1]]\n",
    "                else :\n",
    "                    print(\"Invalid rule detected {}\".format(rule))\n",
    "        indices = train_x.index.values\n",
    "        print(indices)\n",
    "        print(y)\n",
    "        train_y = y.loc[indices]\n",
    "        train_x.reset_index(drop=True)\n",
    "        train_y.reset_index(drop=True)\n",
    "        return train_x, train_y\n",
    "    \n",
    "    def predict(self, X:pd.DataFrame) -> np.array:\n",
    "        p_X = X.copy()\n",
    "        p_X['prediction'] = np.nan\n",
    "        for category, rule in self.rules.items():\n",
    "            if category not in X.columns.values: continue\n",
    "            for rule in rules:\n",
    "                if rule[0] == \"=\":\n",
    "                    p_X.loc[p_X[category]==rule[1], 'prediction'] = rule[2]\n",
    "                elif rule[0] == '<' :\n",
    "                    p_X.loc[p_X[category] < rule[1], 'prediction'] = rule[2]\n",
    "                elif rule[0] == '<=' :\n",
    "                    p_X.loc[p_X[category] <= rule[1], 'prediction'] = rule[2]\n",
    "        if len(p_X.loc[p_X['prediction'].isna()].index != 0):\n",
    "            base_X = p_X.loc[p_X['prediction'].isna()].copy()\n",
    "            base_X.drop('prediction', axis=1, inplace=True)\n",
    "            p_X.loc[p_X['prediction'].isna(), 'prediction'] = self.base_model.predict(base_X)\n",
    "            return p_X['prediction'].values  \n",
    "        \n",
    "    def get_params(self, deep: bool = True) -> Dict:\n",
    "        \"\"\"Return the model's and base model's parameters.\n",
    "        Args:\n",
    "            deep: Whether to recursively return the base model's parameters.\n",
    "        Returns\n",
    "            Dict: The model's parameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {'base_model': self.base_model,\n",
    "                  'outcome_range': self.outcome_range,\n",
    "                  'rules': self.rules\n",
    "                 }\n",
    "    \n",
    "        params.update(self.base_model.get_params(deep=deep))\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Sets parameters for the model and base model.\n",
    "        Args:\n",
    "            **params: Optional keyword arguments.\n",
    "        \"\"\"\n",
    "                  \n",
    "        parameters = params\n",
    "        param_keys = parameters.keys()\n",
    "        \n",
    "        if 'base_model' in param_keys:\n",
    "            value = parameters.pop('base_model')\n",
    "            self.base_model = value\n",
    "            \n",
    "        if 'rules' in param_keys:\n",
    "            value = parameters.pop('rules')\n",
    "            self.rules = value\n",
    "        \n",
    "        self.base_model.set_params(**parameters)\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bcfc1eb0-e11f-4945-98b3-c855fbd32485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self):\n",
    "        # self.preprocess = preProcess()\n",
    "        self.feature_list = []\n",
    "    def isNumeric(self, char):\n",
    "        import re\n",
    "        regex = re.findall(r\"^[-+]?(?:\\d*\\.\\d+|\\d+$)\", char)\n",
    "        if regex:\n",
    "            return True\n",
    "        for c in char:\n",
    "            if not c.isdigit():\n",
    "                return False\n",
    "        return True\n",
    "    def isOnlyAlpha(self, char):\n",
    "        regex = re.findall(r\"[A-Za-z]+$\", char)\n",
    "        if regex:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def isBlank(self, each_element):\n",
    "        if not each_element or each_element == 'UNKNOWN' or each_element.isspace() or each_element == 'NULL' or each_element == ' ' or each_element == '' or each_element == None or each_element == \"\" or each_element ==\" \":\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def specialCharacters(self,char):\n",
    "        import re\n",
    "        regex = re.findall(r'[\\w]',char)\n",
    "        if regex:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "    def isDate(self, string, fuzzy=False):\n",
    "        \"\"\"\n",
    "        Return whether the string can be interpreted as a date.\n",
    "\n",
    "        :param string: str, string to check for date\n",
    "        :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "        \"\"\"\n",
    "        try: \n",
    "            parse(string, fuzzy=fuzzy)\n",
    "            return True\n",
    "\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def noSpecialCharacters(self, char):\n",
    "        noSpecialChars = 0\n",
    "        noSpecialChars =  len(char) - len( re.findall('[\\w]', char) ) + len(re.findall('[-_]+',char))\n",
    "        return noSpecialChars\n",
    "    \n",
    "    def isSpace(self, char):\n",
    "        if \" \" in char:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def tokenize( self, string, separator = ',', quote = '\"' ):\n",
    "        \"\"\"\n",
    "        Split a comma separated string into a List of strings.\n",
    "\n",
    "        Separator characters inside the quotes are ignored.\n",
    "\n",
    "        :param string: A string to be split into chunks\n",
    "        :param separator: A separator character\n",
    "        :param quote: A character to define beginning and end of the quoted string\n",
    "        :return: A list of strings, one element for every chunk\n",
    "        \"\"\"\n",
    "        comma_separated_list = []\n",
    "\n",
    "        chunk = ''\n",
    "        in_quotes = False\n",
    "\n",
    "        for character in string:\n",
    "            if character == separator and not in_quotes:\n",
    "                comma_separated_list.append(chunk)\n",
    "                chunk = ''\n",
    "\n",
    "            else:\n",
    "                chunk += character\n",
    "                if character == quote:\n",
    "                    in_quotes = False if in_quotes else True\n",
    "        # print(chunk)\n",
    "        # print(chunk.replace('\"',''))\n",
    "        \n",
    "        comma_separated_list.append(chunk.replace('\"',''))\n",
    "        return comma_separated_list\n",
    "    \n",
    "    def featureList(self, file_name):\n",
    "        file = open(file_name, 'r')\n",
    "        lines = file.readlines()\n",
    "        feature_list = []\n",
    "        feature_list_vector = []\n",
    "        line = lines[0]\n",
    "        each_row_elements = self.tokenize(line)\n",
    "        num_numerics = 0\n",
    "        num_alphs = 0\n",
    "        num_null = 0\n",
    "        bool_date = 0\n",
    "        bool_specialChar = 0\n",
    "        \n",
    "        for each_element in each_row_elements:\n",
    "            each_element = each_element.strip('\\\"')\n",
    "            if self.isBlank(each_element):\n",
    "                num_null = 1\n",
    "            elif not self.isNumeric(each_element):\n",
    "                num_alphs = 1\n",
    "            else:\n",
    "                num_numerics = 1\n",
    "            bool_specialChar = 1 if self.specialCharacters(each_element) else 0\n",
    "            bool_space = self.isSpace(each_element)\n",
    "        self.feature_list.append([num_numerics,num_null,num_alphs,bool_specialChar,bool_space])\n",
    "        \n",
    "    def featureVector(self) -> pd.DataFrame:\n",
    "        # scaler = StandardScaler()\n",
    "        # self.feature_list = scaler.fit_transform(self.feature_list)\n",
    "        feature_vector = pd.DataFrame(self.feature_list, columns = ['num_numerics','num_null','num_alphs','bool_specialChar','bool_space'])\n",
    "        return feature_vector\n",
    "    \n",
    "    def constructFeatureFile(self, filename):\n",
    "        self.featureList(filename)\n",
    "        df_feature = self.featureVector()\n",
    "        return df_feature\n",
    "    \n",
    "    def returnHeader(self, filename, pred):\n",
    "        if pred == 1:\n",
    "            file = open(filename, 'r')\n",
    "            lines = file.readlines()\n",
    "            line = lines[0]\n",
    "            each_row_elements = self.tokenize(line)\n",
    "            return each_row_elements\n",
    "        else :\n",
    "            return []\n",
    "    \n",
    "    def constructFeatureVector(self, csvfilename):\n",
    "        df = pd.read_csv(csvfilename)\n",
    "        file_names = df['file_name']\n",
    "        headers = df['has_header']\n",
    "        header_flags = []\n",
    "        \n",
    "        for file_name, header in zip(file_names, headers):\n",
    "            file = 'data/'+file_name\n",
    "            self.featureList(file)\n",
    "            if header == 'yes':\n",
    "                header_flags.append(1)\n",
    "            else:\n",
    "                header_flags.append(0)\n",
    "        df_feature = self.featureVector()\n",
    "        df_feature['has_header'] = header_flags\n",
    "        return df_feature\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c578081f-fb66-4abd-bcc9-224e05990788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_numerics  num_null  num_alphs  bool_specialChar  bool_space  \\\n",
      "0               0         0          1                 1       False   \n",
      "1               0         0          1                 1       False   \n",
      "2               0         0          1                 1       False   \n",
      "3               0         0          1                 1       False   \n",
      "4               1         0          1                 1       False   \n",
      "..            ...       ...        ...               ...         ...   \n",
      "395             0         0          1                 1       False   \n",
      "396             0         0          1                 1       False   \n",
      "397             0         0          1                 1       False   \n",
      "398             1         1          1                 0       False   \n",
      "399             1         1          1                 1        True   \n",
      "\n",
      "     has_header  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             0  \n",
      "..          ...  \n",
      "395           1  \n",
      "396           1  \n",
      "397           1  \n",
      "398           0  \n",
      "399           0  \n",
      "\n",
      "[400 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = Features().constructFeatureVector('header_information.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e843207a-a255-42ae-85d2-d7b207bb44d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_numerics  num_null  num_alphs  bool_specialChar  bool_space\n",
      "0               0         0          1                 1       False\n",
      "1               0         0          1                 1       False\n",
      "2               0         0          1                 1       False\n",
      "3               0         0          1                 1       False\n",
      "4               1         0          1                 1       False\n",
      "..            ...       ...        ...               ...         ...\n",
      "395             0         0          1                 1       False\n",
      "396             0         0          1                 1       False\n",
      "397             0         0          1                 1       False\n",
      "398             1         1          1                 0       False\n",
      "399             1         1          1                 1        True\n",
      "\n",
      "[400 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns = ['has_header'])\n",
    "y = data['has_header']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8565191-b47f-4ba9-9d9c-f3edd2e059fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "395    1\n",
      "396    1\n",
      "397    1\n",
      "398    0\n",
      "399    0\n",
      "Name: has_header, Length: 400, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5ef660e-184e-4bee-8686-d10468d6dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "990a48cf-70e7-4d1d-83ff-e51a29fc9ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     num_numerics  num_null  num_alphs  bool_specialChar  bool_space\n",
      "261             0         0          1                 1       False\n",
      "118             0         0          1                 1       False\n",
      "48              0         0          1                 1       False\n",
      "156             0         1          1                 0       False\n",
      "211             0         1          0                 0       False\n",
      "..            ...       ...        ...               ...         ...\n",
      "353             0         0          1                 1       False\n",
      "186             1         1          1                 1        True\n",
      "111             0         0          1                 1       False\n",
      "332             0         0          1                 1       False\n",
      "396             0         0          1                 1       False\n",
      "\n",
      "[320 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96401dc5-2086-4259-9d06-9850219ce534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb118ef-372c-4d47-8457-5de3a08649a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=50, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "rules = {\" num_null\": [\n",
    "                            (\"=\", 0, 0)\n",
    "                         ]}\n",
    "hybrid_model = RuleAugmentedRFE(model, rules)\n",
    "hybrid_model.fit(X_train, y_train)\n",
    "predictions = hybrid_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f747ffe-7ca6-4ccf-89eb-330c05c0bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = hybrid_model.predict(X_test)\n",
    "# Probabilities for each class\n",
    "\n",
    "print(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081cafb-6f02-4339-bf5f-9250c7987ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d6474-be14-474c-92ed-1b21fd29c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hybrid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ada8766a-65a0-47a6-bbaa-28b712a77b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "hybrid_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10a9518b-9546-4837-a171-2e4054b83630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Random Forest Trained on Original Data\n",
      "Average absolute error: 0.03 degrees.\n",
      "169    1\n",
      "185    0\n",
      "164    0\n",
      "250    1\n",
      "83     1\n",
      "      ..\n",
      "221    1\n",
      "356    1\n",
      "154    1\n",
      "66     1\n",
      "94     1\n",
      "Name: has_header, Length: 80, dtype: int64\n",
      "Mean Absolute Error: 0.025\n",
      "Mean Squared Error: 0.025\n",
      "Root Mean Squared Error: 0.15811388300841897\n"
     ]
    }
   ],
   "source": [
    "errors = abs(rf_predictions - y_test)\n",
    "print('Metrics for Random Forest Trained on Original Data')\n",
    "print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "print(y_test)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(rf_predictions, y_test))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(rf_predictions, y_test))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, rf_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe2efe47-533c-4a1b-8862-a9bf71a41b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  2]\n",
      " [ 0 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        21\n",
      "           1       0.97      1.00      0.98        59\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.98      0.95      0.97        80\n",
      "weighted avg       0.98      0.97      0.97        80\n",
      "\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,rf_predictions))\n",
    "print(classification_report(y_test,rf_predictions))\n",
    "print(accuracy_score(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ed72332b-a24e-4280-968e-b7c1a5fb26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_header(file_name):\n",
    "    data = Features().constructFeatureFile(file_name)\n",
    "    predictions = hybrid_model.predict(data)\n",
    "    header_list  = Features().returnHeader(file_name, predictions)\n",
    "    header_flag = \"yes\" if predictions == 1 else \"no\"\n",
    "    return { \"has_header\": header_flag, \n",
    "      \"header\": header_list} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ebba702f-4f9c-4e36-b87c-08550a229f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_header': 'no', 'header': []}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_header('data/058c1376-87a3-4ae3-8b1a-2d2adfb21a33.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1ef03-209f-4f53-b474-650356823fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
